"""
tab_edu_hub.py â€” Education Hub: Concept Cards, Glossary, Formula Sheet,
Decision Guide, and MCQ Quiz for Hypothesis Testing in Finance.
"""
import streamlit as st
from components import (
    render_card, ib, render_ib, fml, bdg,
    hl, gt, rt2, lb_t, mut_t, txt_s, p,
    two_col, three_col, table_html,
    section_heading, steps_html,
    FH, FB, FM, TXT, NO_SEL,
)
from tab_explainers import explainer_edu_hub

# â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _gold(t):  return f'<span style="color:#FFD700;-webkit-text-fill-color:#FFD700;font-weight:600">{t}</span>'
def _blue(t):  return f'<span style="color:#ADD8E6;-webkit-text-fill-color:#ADD8E6;font-weight:600">{t}</span>'
def _green(t): return f'<span style="color:#28a745;-webkit-text-fill-color:#28a745;font-weight:600">{t}</span>'
def _red(t):   return f'<span style="color:#dc3545;-webkit-text-fill-color:#dc3545;font-weight:600">{t}</span>'
def _mono(t):  return f'<span style="font-family:{FM};color:#64ffda;-webkit-text-fill-color:#64ffda">{t}</span>'

def _concept_card(icon, title, title_color, border, bg, items):
    rows = "".join(
        f'<div style="display:flex;align-items:flex-start;gap:9px;margin-bottom:8px;{NO_SEL}">'
        f'{item["badge"]}'
        f'<span style="font-family:{FB};font-size:.87rem;color:#e6f1ff;'
        f'-webkit-text-fill-color:#e6f1ff;line-height:1.55">{item["text"]}</span></div>'
        for item in items
    )
    return (
        f'<div style="background:{bg};border-left:4px solid {border};border-radius:10px;'
        f'padding:16px 17px;height:100%;user-select:none;-webkit-user-select:none">'
        f'<div style="font-family:{FH};font-size:1rem;color:{title_color};'
        f'-webkit-text-fill-color:{title_color};font-weight:700;margin-bottom:12px">'
        f'{icon} {title}</div>'
        f'{rows}</div>'
    )

def _term_card(term, symbol, definition, formula, example, badge_label, badge_variant, finance_note):
    sym = (f'<span style="font-family:{FM};font-size:.8rem;color:#64ffda;'
           f'-webkit-text-fill-color:#64ffda;margin-left:8px">{symbol}</span>') if symbol else ""
    return (
        f'<div style="background:#112240;border:1px solid #1e3a5f;border-radius:10px;'
        f'padding:15px 17px;margin-bottom:13px;{NO_SEL}">'
        f'<div style="display:flex;align-items:center;gap:8px;margin-bottom:7px">'
        f'<span style="font-family:{FH};font-size:1rem;color:#FFD700;'
        f'-webkit-text-fill-color:#FFD700;font-weight:700">{term}</span>'
        f'{sym}{bdg(badge_label, badge_variant)}</div>'
        f'<div style="font-family:{FB};font-size:.89rem;color:#e6f1ff;'
        f'-webkit-text-fill-color:#e6f1ff;line-height:1.65;margin-bottom:6px">{definition}</div>'
        + fml(formula) +
        f'<div style="background:rgba(255,215,0,0.08);border-left:3px solid #FFD700;'
        f'border-radius:5px;padding:8px 11px;margin:8px 0;font-family:{FB};font-size:.84rem;'
        f'color:#e6f1ff;-webkit-text-fill-color:#e6f1ff;line-height:1.55">'
        f'<span style="color:#FFD700;-webkit-text-fill-color:#FFD700;font-weight:600">Example: </span>{example}</div>'
        f'<div style="font-family:{FB};font-size:.83rem;color:#ADD8E6;'
        f'-webkit-text-fill-color:#ADD8E6;margin-top:6px">'
        f'<span style="font-weight:600">ğŸ“ˆ Finance: </span>{finance_note}</div>'
        f'</div>'
    )

def _row(label, value):
    return (
        f'<div style="display:flex;justify-content:space-between;padding:4px 0;'
        f'border-bottom:1px solid rgba(30,58,95,0.5);{NO_SEL}">'
        f'<span style="color:#8892b0;-webkit-text-fill-color:#8892b0;'
        f'font-family:{FB};font-size:.83rem">{label}</span>'
        f'<span style="font-family:{FM};color:#e6f1ff;-webkit-text-fill-color:#e6f1ff;'
        f'font-size:.83rem">{value}</span></div>'
    )

def _mini_card(title, color, rows_html):
    return (
        f'<div style="background:rgba(0,51,102,0.45);border:1px solid {color};'
        f'border-radius:8px;padding:14px 15px;{NO_SEL}">'
        f'<div style="color:{color};-webkit-text-fill-color:{color};'
        f'font-family:{FH};font-size:.95rem;font-weight:700;margin-bottom:10px">{title}</div>'
        f'<div style="font-family:{FM};font-size:.82rem">{rows_html}</div></div>'
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONCEPT_CARDS = {
    "Core Concepts": [
        dict(icon="ğŸ¯", title="Hypothesis Framework", title_color="#FFD700",
             border="#FFD700", bg="rgba(255,215,0,0.07)", items=[
                dict(badge=bdg("Hâ‚€ Null","blue"),       text="Default assumption â€” 'nothing changed'. Always contains = sign."),
                dict(badge=bdg("Hâ‚ Alternative","gold"),text="The claim under investigation â€” direction sets the test type."),
                dict(badge=bdg("Î± Type I Error","red"),  text="P(Reject true Hâ‚€) â€” your false alarm tolerance."),
                dict(badge=bdg("Î² Type II Error","gold"),text="P(Miss real effect) â€” Power = 1 âˆ’ Î²."),
                dict(badge=bdg("p-value","blue"),        text="P(result this extreme | Hâ‚€ true). Small â†’ strong evidence."),
                dict(badge=bdg("Test statistic","green"),text="z or t: how many SE from Hâ‚€. Compared to critical value."),
            ]),
        dict(icon="ğŸ“", title="Test Selection", title_color="#ADD8E6",
             border="#ADD8E6", bg="rgba(0,51,102,0.5)", items=[
                dict(badge=bdg("Right-tailed","gold"), text="Hâ‚: Î¼ > Î¼â‚€ â€” reject in RIGHT tail only. Critical: +1.645 at Î±=5%."),
                dict(badge=bdg("Left-tailed","red"),   text="Hâ‚: Î¼ < Î¼â‚€ â€” reject in LEFT tail only. Critical: âˆ’1.645 at Î±=5%."),
                dict(badge=bdg("Two-tailed","blue"),   text="Hâ‚: Î¼ â‰  Î¼â‚€ â€” reject in BOTH tails. Critical: Â±1.960 at Î±=5%."),
                dict(badge=bdg("z-test","green"),      text="Use when Ïƒ is known or n â‰¥ 30 (CLT applies)."),
                dict(badge=bdg("t-test","blue"),       text="Use when Ïƒ is unknown. df = n âˆ’ 1. t â†’ z as n â†’ âˆ."),
                dict(badge=bdg("Rule","gold"),         text="Pre-commit to test type BEFORE seeing data to avoid p-hacking."),
            ]),
        dict(icon="âš ", title="Error Types", title_color="#dc3545",
             border="#dc3545", bg="rgba(220,53,69,0.08)", items=[
                dict(badge=bdg("Type I (Î±)","red"),       text="Reject true Hâ‚€. 'False positive.' Controlled by Î±."),
                dict(badge=bdg("Type II (Î²)","gold"),     text="Fail to reject false Hâ‚€. 'Missed signal.' Increases as Î± shrinks."),
                dict(badge=bdg("Power","green"),          text="1 âˆ’ Î². Probability of detecting a real effect. Increases with n."),
                dict(badge=bdg("Trade-off","purple" if False else "blue"), text="Lower Î± â†’ fewer false alarms but lower power. Balance is key."),
                dict(badge=bdg("Finance: Type I","red"),  text="Declare fund has alpha when it doesn't â†’ invest in dud manager."),
                dict(badge=bdg("Finance: Type II","gold"),text="Miss a genuinely skilled manager â†’ lost opportunity."),
            ]),
    ],
    "z-Test & t-Test": [
        dict(icon="ğŸ“", title="z-Test (Ïƒ Known)", title_color="#FFD700",
             border="#FFD700", bg="rgba(255,215,0,0.07)", items=[
                dict(badge=bdg("Formula","gold"),       text="z = (xÌ„ âˆ’ Î¼â‚€) / (Ïƒ/âˆšn)"),
                dict(badge=bdg("SE","blue"),            text="Standard Error = Ïƒ/âˆšn â€” precision of sample mean."),
                dict(badge=bdg("Î±=5%, right","green"),  text="Reject if z > +1.645"),
                dict(badge=bdg("Î±=5%, left","red"),     text="Reject if z < âˆ’1.645"),
                dict(badge=bdg("Î±=5%, two","blue"),     text="Reject if |z| > 1.960"),
                dict(badge=bdg("When","gold"),          text="Ïƒ known (large historical dataset) or n â‰¥ 30 by CLT."),
            ]),
        dict(icon="ğŸ“Š", title="t-Test (Ïƒ Unknown)", title_color="#ADD8E6",
             border="#ADD8E6", bg="rgba(0,51,102,0.5)", items=[
                dict(badge=bdg("Formula","blue"),       text="t = (xÌ„ âˆ’ Î¼â‚€) / (s/âˆšn)"),
                dict(badge=bdg("df","gold"),            text="Degrees of freedom = n âˆ’ 1. Larger df â†’ closer to z."),
                dict(badge=bdg("Heavier tails","red"),  text="t-distribution is wider than normal â€” harder to reject Hâ‚€."),
                dict(badge=bdg("Î±=5%, df=30","blue"),   text="t_crit â‰ˆ Â±2.042 (two-tailed) â€” wider than z's Â±1.960."),
                dict(badge=bdg("Convergence","green"),  text="As n â†’ âˆ, t_crit â†’ z_crit. t-test is always safe."),
                dict(badge=bdg("Finance use","gold"),   text="Bond duration, credit ratio, or any metric where Ïƒ is estimated."),
            ]),
        dict(icon="ğŸ”¢", title="Critical Values Quick Ref", title_color="#28a745",
             border="#28a745", bg="rgba(40,167,69,0.08)", items=[
                dict(badge=bdg("1.645","gold"),   text="One-tail z at Î±=5%  |  Two-tail z at Î±=10%"),
                dict(badge=bdg("1.960","blue"),   text="Two-tail z at Î±=5%"),
                dict(badge=bdg("2.326","gold"),   text="One-tail z at Î±=1%"),
                dict(badge=bdg("2.576","red"),    text="Two-tail z at Î±=1%"),
                dict(badge=bdg("Memory aid","green"), text="1.645 â†’ 1.96 â†’ 2.33 â†’ 2.576 (memorise these 4!)"),
                dict(badge=bdg("t > z always","blue"),text="t critical values always exceed z for same Î± and finite df."),
            ]),
    ],
    "Finance Applications": [
        dict(icon="ğŸ’¹", title="Portfolio & Alpha Tests", title_color="#FFD700",
             border="#FFD700", bg="rgba(255,215,0,0.07)", items=[
                dict(badge=bdg("Fund Alpha","gold"),     text="Hâ‚€: Î±=0 | Hâ‚: Î±>0 â†’ Right-tailed t-test on regression intercept."),
                dict(badge=bdg("CAPM Beta","blue"),      text="Hâ‚€: Î²=1 | Hâ‚: Î²â‰ 1 â†’ Two-tailed t-test. t=(Î²Ì‚âˆ’1)/SE(Î²Ì‚)."),
                dict(badge=bdg("Sharpe Ratio","green"),  text="Hâ‚€: SRâ‰¤SRâ‚€ â†’ Jobson-Korkie test for risk-adj performance."),
                dict(badge=bdg("Return Mean","gold"),    text="Hâ‚€: Î¼=benchmark â†’ One or two-tailed depending on prior belief."),
                dict(badge=bdg("VaR Backtest","red"),    text="Kupiec test: binomial test on breach frequency vs 5%."),
                dict(badge=bdg("Practical tip","blue"),  text="Always state Hâ‚€ and Hâ‚ before examining data â€” no p-hacking."),
            ]),
        dict(icon="ğŸ¦", title="Credit & Fixed Income", title_color="#ADD8E6",
             border="#ADD8E6", bg="rgba(0,51,102,0.5)", items=[
                dict(badge=bdg("Default Rate","red"),    text="Hâ‚€: pâ‰¤2% | Hâ‚: p>2% â†’ Right-tailed binomial/z-test."),
                dict(badge=bdg("Bond Duration","blue"),  text="Hâ‚€: D=7yr | Hâ‚: Dâ‰ 7yr â†’ Two-tailed t-test post-rebalancing."),
                dict(badge=bdg("Yield Spread","gold"),   text="Hâ‚€: spread unchanged â†’ Two-tailed test after macro event."),
                dict(badge=bdg("NPA Ratio","red"),       text="Hâ‚€: NPAâ‰¤3% | Hâ‚: NPA>3% â†’ Right-tailed t on quarterly data."),
                dict(badge=bdg("Convexity","blue"),      text="Test whether portfolio convexity target is met post-trade."),
                dict(badge=bdg("Capital Adequacy","green"),text="Hâ‚€: CARâ‰¥8% â†’ Left-tailed â€” test for regulatory compliance."),
            ]),
    ],
}

GLOSSARY = [
    dict(term="Null Hypothesis (Hâ‚€)", symbol=None,
         definition="The default assumption â€” 'no change', 'no effect', 'equals benchmark'. Always contains an equality (=, â‰¤, â‰¥). We never 'prove' Hâ‚€; we either reject it or fail to reject it.",
         formula="Hâ‚€: Î¼ = Î¼â‚€  (e.g. Hâ‚€: mean return = 12%)",
         example="Hâ‚€: A mutual fund's average annual return equals the Nifty50 benchmark return of 12%.",
         badge_label="Foundation", badge_variant="blue",
         finance_note="In CFA/FRM: always express Hâ‚€ with equality sign. It represents the 'status quo' that the market already prices in."),
    dict(term="Alternative Hypothesis (Hâ‚)", symbol=None,
         definition="The claim under investigation. Its direction (>, <, â‰ ) determines whether the test is right-tailed, left-tailed, or two-tailed. Must be stated BEFORE data collection.",
         formula="Hâ‚: Î¼ > Î¼â‚€  (right)  |  Hâ‚: Î¼ < Î¼â‚€  (left)  |  Hâ‚: Î¼ â‰  Î¼â‚€  (two)",
         example="Hâ‚: The fund's average return > 12% (fund claims to outperform the market).",
         badge_label="Foundation", badge_variant="blue",
         finance_note="Directional Hâ‚ (one-tailed) requires prior theoretical justification â€” e.g. a factor model predicts outperformance."),
    dict(term="z-Statistic", symbol="z = (xÌ„ âˆ’ Î¼â‚€)/(Ïƒ/âˆšn)",
         definition="The test statistic for a z-test. Measures how many standard errors the sample mean is from the hypothesised mean. Follows a standard normal N(0,1) distribution under Hâ‚€.",
         formula="z = (xÌ„ âˆ’ Î¼â‚€) / (Ïƒ/âˆšn)\nSE = Ïƒ/âˆšn  (standard error of the sample mean)",
         example="xÌ„=13.5%, Î¼â‚€=12%, Ïƒ=6%, n=36 â†’ SE=1.0% â†’ z=(13.5âˆ’12)/1.0 = 1.50",
         badge_label="z-Test", badge_variant="gold",
         finance_note="Used in CAPM tests, VaR backtesting, and any large-sample return distribution test where historical Ïƒ is known."),
    dict(term="t-Statistic", symbol="t = (xÌ„ âˆ’ Î¼â‚€)/(s/âˆšn)",
         definition="Test statistic when Ïƒ is unknown. Uses sample standard deviation s. Follows a t-distribution with df = nâˆ’1. Always has heavier tails than z, making it harder to reject Hâ‚€.",
         formula="t = (xÌ„ âˆ’ Î¼â‚€) / (s/âˆšn)     df = n âˆ’ 1\nAs n â†’ âˆ: t â†’ z (t_crit â†’ z_crit)",
         example="Bond duration: xÌ„=7.84, Î¼â‚€=7.0, s=2.94, n=49 â†’ t=(7.84âˆ’7.0)/(2.94/7)=2.0",
         badge_label="t-Test", badge_variant="blue",
         finance_note="Most common in practice â€” population Ïƒ is rarely known. Use t-test as the default for small/medium samples."),
    dict(term="p-value", symbol="P(|T| â‰¥ |t_obs| | Hâ‚€)",
         definition="The probability of observing a test statistic as extreme as the computed one, assuming Hâ‚€ is true. NOT the probability Hâ‚€ is true. Small p-value = strong evidence against Hâ‚€.",
         formula="Right-tailed: p = P(Z > z)\nLeft-tailed:  p = P(Z < z)\nTwo-tailed:   p = 2 Ã— P(Z > |z|)",
         example="z = 1.50 (right-tailed): p = P(Z > 1.50) = 1 âˆ’ 0.9332 = 0.0668. Since 0.0668 > 0.05, fail to reject at Î±=5%.",
         badge_label="Decision", badge_variant="gold",
         finance_note="FRM exam tip: p-value is NOT P(Hâ‚€ is true). It is the probability of the data given Hâ‚€. A common source of exam errors."),
    dict(term="Type I Error (Î±)", symbol="P(Reject Hâ‚€ | Hâ‚€ true)",
         definition="Falsely rejecting a true null hypothesis â€” a 'false positive'. Controlled by setting the significance level Î±. Lower Î± â†’ fewer false alarms, but also lower power.",
         formula="Î± = P(Type I Error) = significance level\nSet by researcher BEFORE testing: typically 1%, 5%, or 10%",
         example="At Î±=5%: if Hâ‚€ is true, there is a 5% chance we still reject it (false alarm) due to sampling variation.",
         badge_label="Error Types", badge_variant="red",
         finance_note="In investment management: Type I error = allocating capital to a manager with no real skill. Lower Î± reduces this risk but makes it harder to identify skilled managers (higher Type II risk)."),
    dict(term="Statistical Power", symbol="Power = 1 âˆ’ Î²",
         definition="The probability of correctly rejecting Hâ‚€ when it is false. Power increases with: larger sample size, larger true effect, higher Î±. One-tailed tests have higher power than two-tailed.",
         formula="Power = 1 âˆ’ P(Type II Error)\nPower = P(Reject Hâ‚€ | Hâ‚€ false)",
         example="Power = 0.85 means: if the fund truly outperforms, we have an 85% chance of detecting this with our test.",
         badge_label="Error Types", badge_variant="green",
         finance_note="Low-power tests miss real market inefficiencies. In quantitative investing, increasing n (more observations) is the primary way to increase power."),
    dict(term="Critical Value", symbol="z_crit or t_crit",
         definition="The threshold value of the test statistic beyond which Hâ‚€ is rejected. Determined by Î±, test direction, and distribution. The 'boundary' of the rejection region.",
         formula="One-tail Î±=5%:  z_crit = +1.645 (right) or âˆ’1.645 (left)\nTwo-tail Î±=5%:  z_crit = Â±1.960\nTwo-tail Î±=1%:  z_crit = Â±2.576",
         example="Testing fund alpha at Î±=5% (right-tailed): reject Hâ‚€ if z > 1.645. A z of 1.5 does NOT cross this threshold.",
         badge_label="Decision Rule", badge_variant="blue",
         finance_note="Memory anchor for CFA/FRM: 1.645 â†’ 1.96 â†’ 2.33 â†’ 2.576. These cover one-tail 5%, two-tail 5%, one-tail 1%, two-tail 1%."),
]

FORMULA_SECTIONS = {
    "z-Test Formulas": [
        ("z-statistic",      "z = (xÌ„ âˆ’ Î¼â‚€) / (Ïƒ/âˆšn)"),
        ("Standard Error",   "SE = Ïƒ / âˆšn"),
        ("Right-tail p",     "p = 1 âˆ’ Î¦(z)"),
        ("Left-tail p",      "p = Î¦(z)"),
        ("Two-tail p",       "p = 2 Ã— [1 âˆ’ Î¦(|z|)]"),
        ("95% CI (known Ïƒ)", "xÌ„ Â± 1.960 Ã— (Ïƒ/âˆšn)"),
    ],
    "t-Test Formulas": [
        ("t-statistic",      "t = (xÌ„ âˆ’ Î¼â‚€) / (s/âˆšn)"),
        ("Degrees of freedom","df = n âˆ’ 1"),
        ("SE (Ïƒ unknown)",   "SE = s / âˆšn"),
        ("95% CI (unknown Ïƒ)","xÌ„ Â± t_crit(df) Ã— (s/âˆšn)"),
        ("Pooled 2-sample t", "t = (xÌ„â‚âˆ’xÌ„â‚‚) / SE_pooled"),
        ("t â†’ z as nâ†’âˆ",    "t(dfâ†’âˆ) = z (same critical values)"),
    ],
    "Critical Values": [
        ("z: one-tail 10%",   "+1.282"),
        ("z: one-tail 5%",    "+1.645"),
        ("z: two-tail 5%",    "Â±1.960"),
        ("z: one-tail 1%",    "+2.326"),
        ("z: two-tail 1%",    "Â±2.576"),
        ("z: two-tail 0.1%",  "Â±3.291"),
    ],
    "Finance-Specific": [
        ("CAPM Beta test",    "t = (Î²Ì‚ âˆ’ 1) / SE(Î²Ì‚)"),
        ("Jensen's Alpha",    "t = Î±Ì‚ / SE(Î±Ì‚)  [right-tailed]"),
        ("VaR Kupiec",        "LR = âˆ’2ln[(1âˆ’p)^(nâˆ’x) Ã— p^x / ...]"),
        ("Sharpe difference", "JK = (SRâ‚âˆ’SRâ‚‚) / SE_JK"),
        ("Bond duration",     "t = (DÌ„ âˆ’ D_target) / (s_D/âˆšn)"),
        ("Default rate",      "z = (pÌ‚ âˆ’ pâ‚€) / âˆš(pâ‚€(1âˆ’pâ‚€)/n)"),
    ],
}

MCQ_BANK = [
    dict(qid="q01", level="Foundation", topic="Core Concepts",
         question="The p-value in hypothesis testing represents:",
         options=["The probability that Hâ‚€ is true",
                  "The probability of observing results this extreme if Hâ‚€ is true",
                  "The significance level Î±",
                  "The probability that Hâ‚ is true"],
         answer=1,
         explanation=f'The p-value = P(data at least this extreme | Hâ‚€ true). It is {_red("NOT")} the probability Hâ‚€ is true â€” a very common misconception. If p < Î±, we reject Hâ‚€.'),
    dict(qid="q02", level="Foundation", topic="Core Concepts",
         question="Which of the following correctly describes a Type I Error?",
         options=["Failing to reject Hâ‚€ when it is false",
                  "Rejecting Hâ‚€ when it is actually true",
                  "Using too small a sample size",
                  "Setting Î± too high"],
         answer=1,
         explanation=f'Type I Error = {_red("False positive")} â€” rejecting a true Hâ‚€. Its probability is exactly Î±, the significance level. In finance: declaring a fund manager has skill when they do not.'),
    dict(qid="q03", level="Foundation", topic="Test Selection",
         question="A fund manager claims their fund returns ARE DIFFERENT from the benchmark (not necessarily better or worse). Which test is appropriate?",
         options=["Right-tailed test",
                  "Left-tailed test",
                  "Two-tailed test",
                  "No test needed â€” just compare means"],
         answer=2,
         explanation=f'Hâ‚: Î¼ â‰  benchmark â†’ {_gold("Two-tailed test")}. The claim is non-directional (just "different"), so we check both tails. Î± is split as Î±/2 per tail. Critical values are Â±1.960 at Î±=5%.'),
    dict(qid="q04", level="Foundation", topic="Critical Values",
         question="At Î± = 5%, what is the critical value for a one-tailed (right) z-test?",
         options=["1.282", "1.645", "1.960", "2.576"],
         answer=1,
         explanation=f'{_gold("1.645")} is the one-tailed z-critical value at Î±=5%. For two-tailed at Î±=5%, it is Â±1.960. Memory anchor: 1.645 â†’ 1.96 â†’ 2.33 â†’ 2.576.'),
    dict(qid="q05", level="Foundation", topic="z vs t-test",
         question="When should you use a t-test instead of a z-test?",
         options=["When the sample size is very large (n > 100)",
                  "When the population standard deviation (Ïƒ) is unknown",
                  "When the data is normally distributed",
                  "When testing proportions"],
         answer=1,
         explanation=f'Use t-test when {_gold("Ïƒ is unknown")} and must be estimated by s. The t-distribution has heavier tails than z, accounting for the extra uncertainty. With large n, t â†’ z.'),
    dict(qid="q06", level="Intermediate", topic="Calculation",
         question="xÌ„ = 14%, Î¼â‚€ = 12%, Ïƒ = 8%, n = 64. What is the z-statistic for testing Hâ‚: Î¼ > 12%?",
         options=["1.00", "2.00", "0.25", "1.50"],
         answer=1,
         explanation=f'SE = Ïƒ/âˆšn = 8/8 = 1.0%. z = (14 âˆ’ 12)/1.0 = {_gold("2.00")}. Since 2.00 > 1.645, reject Hâ‚€ at Î±=5% (right-tailed).'),
    dict(qid="q07", level="Intermediate", topic="Test Selection",
         question="A risk manager tests whether a portfolio's VaR INCREASED after a new regulation. Which test?",
         options=["Two-tailed (Hâ‚: VaR â‰  old)",
                  "Right-tailed (Hâ‚: VaR > old)",
                  "Left-tailed (Hâ‚: VaR < old)",
                  "No formal test needed"],
         answer=1,
         explanation=f'The manager specifically predicts VaR {_red("increased")} â€” a directional claim. Hâ‚: VaR > old â†’ {_gold("Right-tailed test")}. All Î± is in the right tail, giving maximum power to detect an increase.'),
    dict(qid="q08", level="Intermediate", topic="Errors",
         question="A bank sets Î± = 1% for its credit approval model to minimise false approvals. What is the direct consequence?",
         options=["Higher power to detect bad borrowers",
                  "Increased Type II Error (more good borrowers rejected)",
                  "Reduced sample size needed",
                  "Lower standard errors"],
         answer=1,
         explanation=f'Lowering Î± from 5% to 1% reduces Type I Error (fewer false approvals) but {_red("increases Type II Error")} â€” good borrowers are more frequently denied credit (false rejections). Power decreases.'),
    dict(qid="q09", level="Intermediate", topic="p-value",
         question="A bond duration test gives z = 1.75, two-tailed, Î± = 5%. p-value â‰ˆ 0.080. The conclusion is:",
         options=["Reject Hâ‚€ â€” duration has changed",
                  "Fail to reject Hâ‚€ â€” insufficient evidence of change",
                  "Cannot conclude without knowing the sample size",
                  "Reject Hâ‚€ because z > 1.645"],
         answer=1,
         explanation=f'p = 0.080 > Î± = 0.05 â†’ {_green("Fail to reject Hâ‚€")}. Also: |z| = 1.75 < 1.960 (two-tail critical). Note: 1.75 > 1.645, but 1.645 is the ONE-tailed critical value, not two-tailed. A common trap!'),
    dict(qid="q10", level="Intermediate", topic="Finance",
         question="CAPM beta = 1.18, SE(Î²) = 0.12. Testing Hâ‚€: Î² = 1 vs Hâ‚: Î² â‰  1 at Î± = 5%. Decision?",
         options=["Reject Hâ‚€ â€” beta is significantly different from 1",
                  "Fail to reject â€” beta is not significantly different from 1",
                  "Cannot tell without the p-value",
                  "Use a one-tailed test instead"],
         answer=0,
         explanation=f't = (1.18 âˆ’ 1.0)/0.12 = 0.18/0.12 = {_gold("1.50")}. With large df, t_crit â‰ˆ Â±1.96. Since 1.50 < 1.96, {_green("Fail to reject Hâ‚€")}. Beta is not statistically different from 1 at Î±=5%. (The correct answer is B.)'),
    dict(qid="q11", level="Advanced", topic="Power",
         question="A fund wants to test alpha using n = 36 monthly returns. Power is low. Which action MOST increases power without changing Î±?",
         options=["Switch from two-tailed to one-tailed test",
                  "Increase sample size to n = 100",
                  "Lower Î± from 5% to 10%",
                  "Both A and B would equally increase power"],
         answer=3,
         explanation=f'Both increasing n and switching to one-tailed test increase power. {_gold("Increasing n")} improves power for any test type. {_gold("One-tailed test")} concentrates all Î± in one tail, reducing the critical value from 1.96 to 1.645. Combined, they have the greatest effect.'),
    dict(qid="q12", level="Advanced", topic="Finance",
         question="A portfolio manager's monthly alpha is 0.4% with SE = 0.25%, n = 60 months, Î± = 1%. Is the alpha statistically significant?",
         options=["Yes â€” t = 1.60 > 1.645",
                  "No â€” t = 1.60 < 2.326 (one-tail z at Î±=1%)",
                  "Yes â€” t = 1.60 > 1.282",
                  "Insufficient information"],
         answer=1,
         explanation=f't = 0.4/0.25 = {_gold("1.60")}. This is a right-tailed test (Hâ‚: Î± > 0). At Î±=1%, one-tail z_crit = 2.326. Since 1.60 < 2.326, {_red("Fail to reject")} at Î±=1%. Note: would reject at Î±=5% (z_crit=1.645 is barely not met, but very close) and would reject at Î±=10% (z_crit=1.282).'),
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION RENDERERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _section_concept_cards():
    theme = st.selectbox("Theme", list(CONCEPT_CARDS.keys()), key="edu_theme")
    cards = CONCEPT_CARDS[theme]
    if len(cards) == 2:
        cols = st.columns(2)
        for col, card in zip(cols, cards):
            col.html(_concept_card(**card))
    else:
        cols = st.columns(3)
        for col, card in zip(cols, cards):
            col.html(_concept_card(**card))

    # Matching formula box per theme
    theme_fmls = {
        "Core Concepts":      ("Core Decision Rule",
                               "Reject Hâ‚€ if:  test stat > critical value\n"
                               "           OR:  p-value < Î±\n\n"
                               "p-value (right):  1 âˆ’ Î¦(z)\n"
                               "p-value (left):   Î¦(z)\n"
                               "p-value (two):    2 Ã— [1 âˆ’ Î¦(|z|)]"),
        "z-Test & t-Test":    ("z vs t Quick Reference",
                               "z = (xÌ„ âˆ’ Î¼â‚€)/(Ïƒ/âˆšn)  [Ïƒ known]\n"
                               "t = (xÌ„ âˆ’ Î¼â‚€)/(s/âˆšn)  [Ïƒ unknown, df=nâˆ’1]\n\n"
                               "Î±=5%: 1-tail z=1.645 | 2-tail z=Â±1.960\n"
                               "Î±=1%: 1-tail z=2.326 | 2-tail z=Â±2.576"),
        "Finance Applications":("Finance Test Reference",
                                "Jensen's alpha:   t = Î±Ì‚/SE(Î±Ì‚)   [right-tailed]\n"
                                "CAPM beta:        t = (Î²Ì‚âˆ’1)/SE(Î²Ì‚) [two-tailed]\n"
                                "Duration shift:   t = (DÌ„âˆ’Dâ‚€)/(s/âˆšn) [two-tailed]\n"
                                "VaR backtest:     Kupiec LR ~ Ï‡Â²(1)"),
    }
    if theme in theme_fmls:
        title, formula_text = theme_fmls[theme]
        render_ib(
            f'<span style="color:#FFD700;-webkit-text-fill-color:#FFD700;font-weight:600">ğŸ“ {title}</span>'
            + fml(formula_text), "gold"
        )


def _section_glossary():
    col1, col2 = st.columns([2, 1])
    search = col1.text_input("ğŸ” Search terms", placeholder="e.g. p-value, critical, Type I...", key="edu_search")
    topic_f = col2.selectbox("Filter by topic", ["All", "Core Concepts", "z-Test", "t-Test", "Decision", "Errors", "Finance"], key="edu_topic")

    TOPIC_MAP = {
        "Core Concepts": ["Null", "Alternative", "Hypothesis"],
        "z-Test":        ["z-Stat", "z-test", "z-"],
        "t-Test":        ["t-Stat", "t-test", "t-"],
        "Decision":      ["p-value", "Critical"],
        "Errors":        ["Type I", "Type II", "Power"],
        "Finance":       ["CAPM", "Alpha", "Duration", "Finance"],
    }

    filtered = GLOSSARY
    if search.strip():
        s = search.lower()
        filtered = [t for t in filtered
                    if s in t["term"].lower() or s in t["definition"].lower()
                    or s in (t.get("finance_note") or "").lower()]
    if topic_f != "All":
        kws = TOPIC_MAP.get(topic_f, [])
        filtered = [t for t in filtered if any(k.lower() in t["term"].lower() for k in kws)]

    if not filtered:
        render_ib(rt2("No terms match. Try a broader search."), "red")
        return

    st.html(f'<div style="color:#8892b0;-webkit-text-fill-color:#8892b0;font-family:{FB};'
            f'font-size:.82rem;margin-bottom:10px;{NO_SEL}">'
            f'Showing {len(filtered)} of {len(GLOSSARY)} terms</div>')
    for t in filtered:
        st.html(_term_card(**t))


def _section_formula_sheet():
    secs = list(FORMULA_SECTIONS.items())
    cols1 = st.columns(2)
    for col, (title, rows) in zip(cols1, secs[:2]):
        rh = "".join(_row(k, v) for k, v in rows)
        col.html(_mini_card(title, "#FFD700", rh))
    cols2 = st.columns(2)
    for col, (title, rows) in zip(cols2, secs[2:]):
        rh = "".join(_row(k, v) for k, v in rows)
        col.html(_mini_card(title, "#ADD8E6", rh))

    section_heading("ğŸ“Š Critical Values Table (z-distribution)")
    st.html(table_html(
        ["Î±", "One-Tail z", "Two-Tail z (Â±)", "t (df=30)", "t (df=60)", "t (df=âˆ)"],
        [
            [txt_s("0.10"), hl("1.282"), hl("1.645"), txt_s("1.310"), txt_s("1.296"), txt_s("1.282")],
            [txt_s("0.05"), hl("1.645"), hl("1.960"), txt_s("2.042"), txt_s("2.000"), txt_s("1.960")],
            [txt_s("0.025"),hl("1.960"), hl("2.241"), txt_s("2.360"), txt_s("2.299"), txt_s("2.241")],
            [txt_s("0.01"), hl("2.326"), hl("2.576"), txt_s("2.750"), txt_s("2.660"), txt_s("2.576")],
            [txt_s("0.005"),hl("2.576"), hl("2.807"), txt_s("3.030"), txt_s("2.915"), txt_s("2.807")],
        ]
    ))
    render_ib(
        f'<span style="color:#ADD8E6;-webkit-text-fill-color:#ADD8E6;font-weight:600">Memory Anchor: </span>'
        + hl("1.645 â†’ 1.96 â†’ 2.33 â†’ 2.576")
        + txt_s(' â€” One-tail 5%, Two-tail 5%, One-tail 1%, Two-tail 1%. These four cover 90% of all finance tests!'),
        "blue"
    )


def _section_decision_guide():
    render_card("ğŸ—º Decision Trees",
        p(f'Use these trees to choose the right test every time.')
    )
    section_heading("1ï¸âƒ£  Which Test Type?")
    st.html(table_html(
        ["Situation", "Hâ‚", "Test Type", "Critical z (Î±=5%)"],
        [
            [txt_s("You predict metric <strong>increased</strong>"),  txt_s("Î¼ > Î¼â‚€"), bdg("Right-tailed","gold"),  hl("+1.645")],
            [txt_s("You predict metric <strong>decreased</strong>"),  txt_s("Î¼ < Î¼â‚€"), bdg("Left-tailed","red"),   hl("âˆ’1.645")],
            [txt_s("You predict metric <strong>changed</strong>"),    txt_s("Î¼ â‰  Î¼â‚€"), bdg("Two-tailed","blue"),   hl("Â±1.960")],
            [txt_s("No prior prediction â€” just investigating"),       txt_s("Î¼ â‰  Î¼â‚€"), bdg("Two-tailed (default)","blue"), hl("Â±1.960")],
        ]
    ))

    section_heading("2ï¸âƒ£  z-test or t-test?")
    st.html(table_html(
        ["Condition", "Use", "Key Difference"],
        [
            [txt_s("Ïƒ (population std dev) is <strong>known</strong>"), bdg("z-test","gold"), txt_s("Standard normal N(0,1) distribution")],
            [txt_s("Ïƒ is <strong>unknown</strong>, use sample s"),       bdg("t-test","blue"), txt_s("t-distribution with df = nâˆ’1, heavier tails")],
            [txt_s("Large sample (n â‰¥ 30) but Ïƒ unknown"),               bdg("t-test (safer)","blue"), txt_s("t â†’ z as n increases. t-test is always valid")],
            [txt_s("Proportion test (pÌ‚ vs pâ‚€)"),                        bdg("z-test","gold"), txt_s("z = (pÌ‚ âˆ’ pâ‚€) / âˆš(pâ‚€(1âˆ’pâ‚€)/n)")],
        ]
    ))

    section_heading("3ï¸âƒ£  Interpreting the Result")
    two_left = ib(
        f'<span style="color:#dc3545;-webkit-text-fill-color:#dc3545;font-weight:700">ğŸ”´ REJECT Hâ‚€ when:</span>'
        + steps_html([
            ("test stat > critical value", f'e.g. z = 2.15 > 1.645 at Î±=5% right-tailed'),
            ("p-value < Î±",               f'e.g. p = 0.032 < 0.05 â†’ statistically significant'),
            ("What it means",             f'Strong evidence against Hâ‚€ at the chosen significance level'),
        ]), "red"
    )
    two_right = ib(
        f'<span style="color:#28a745;-webkit-text-fill-color:#28a745;font-weight:700">ğŸŸ¢ FAIL TO REJECT Hâ‚€ when:</span>'
        + steps_html([
            ("test stat < critical value", f'e.g. z = 1.45 < 1.645 at Î±=5% right-tailed'),
            ("p-value â‰¥ Î±",               f'e.g. p = 0.078 > 0.05 â†’ not statistically significant'),
            ("What it means",             f'Insufficient evidence to reject Hâ‚€ â€” NOT proof Hâ‚€ is true'),
        ]), "green"
    )
    st.html(two_col(two_left, two_right))

    section_heading("4ï¸âƒ£  Finance Test Cheat Sheet")
    st.html(table_html(
        ["Finance Question", "Hâ‚€", "Hâ‚", "Test", "Î± Typical"],
        [
            [txt_s("Does fund generate alpha?"),        txt_s("Î± = 0"), txt_s("Î± > 0"), bdg("Right t","gold"),  txt_s("5%")],
            [txt_s("Is portfolio beta = 1?"),           txt_s("Î² = 1"), txt_s("Î² â‰  1"), bdg("Two-tail t","blue"), txt_s("5%")],
            [txt_s("Has bond duration changed?"),       txt_s("D = target"), txt_s("D â‰  target"), bdg("Two-tail t","blue"), txt_s("1%")],
            [txt_s("Has default rate increased?"),      txt_s("p â‰¤ 2%"), txt_s("p > 2%"), bdg("Right z","red"), txt_s("1%")],
            [txt_s("Did VaR model fail (backtesting)?"),txt_s("breach=5%"), txt_s(">5%"), bdg("Right z/LR","red"), txt_s("5%")],
        ]
    ))


def _section_mcq():
    if "mcq_score" not in st.session_state:
        st.session_state.mcq_score = 0
    if "mcq_answered" not in st.session_state:
        st.session_state.mcq_answered = {}

    c1, c2, c3 = st.columns(3)
    level_f = c1.selectbox("Level", ["All", "Foundation", "Intermediate", "Advanced"], key="mcq_lvl")
    topic_q = c2.selectbox("Topic", ["All"] + sorted(set(q["topic"] for q in MCQ_BANK)), key="mcq_top")
    mode    = c3.radio("Mode", ["ğŸ“– Study (show answers)", "ğŸ¯ Quiz (hide answers)"],
                       key="mcq_mode", horizontal=True)
    study_mode = "Study" in mode

    if st.button("ğŸ”„ Reset Quiz", key="mcq_reset"):
        st.session_state.mcq_score   = 0
        st.session_state.mcq_answered = {}
        st.rerun()

    filtered = MCQ_BANK
    if level_f != "All": filtered = [q for q in filtered if q["level"] == level_f]
    if topic_q != "All": filtered = [q for q in filtered if q["topic"] == topic_q]

    correct   = sum(1 for qid, ans in st.session_state.mcq_answered.items()
                    if ans == next((q["answer"] for q in MCQ_BANK if q["qid"] == qid), -1))
    attempted = len(st.session_state.mcq_answered)
    pct       = (correct / attempted * 100) if attempted else 0
    score_color = "#28a745" if pct >= 80 else "#FFD700" if pct >= 60 else "#dc3545"

    st.html(
        f'<div style="display:flex;gap:16px;align-items:center;margin-bottom:12px;{NO_SEL}">'
        f'<span style="font-family:{FH};color:{score_color};-webkit-text-fill-color:{score_color};'
        f'font-size:1.1rem;font-weight:700">Score: {correct}/{attempted}</span>'
        + (f'<span style="font-family:{FM};color:{score_color};-webkit-text-fill-color:{score_color};'
           f'font-size:.9rem">({pct:.0f}%)</span>' if attempted else "")
        + f'<span style="font-family:{FB};color:#8892b0;-webkit-text-fill-color:#8892b0;'
          f'font-size:.82rem">{len(filtered)} question(s) shown</span></div>'
    )

    for q in filtered:
        qid     = q["qid"]
        answered = st.session_state.mcq_answered.get(qid)

        # Header colour
        if answered is None:
            hdr_col, hdr_bg = "#ADD8E6", "rgba(0,51,102,0.4)"
        elif answered == q["answer"]:
            hdr_col, hdr_bg = "#28a745", "rgba(40,167,69,0.12)"
        else:
            hdr_col, hdr_bg = "#dc3545", "rgba(220,53,69,0.12)"

        lv_badge = bdg(q["level"],
                       "green" if q["level"]=="Foundation" else
                       "gold"  if q["level"]=="Intermediate" else "red")

        st.html(
            f'<div style="background:{hdr_bg};border-left:4px solid {hdr_col};border-radius:8px;'
            f'padding:12px 15px;margin-bottom:4px;{NO_SEL}">'
            f'<div style="display:flex;align-items:center;gap:8px;margin-bottom:7px">'
            f'{lv_badge}{bdg(q["topic"],"blue")}'
            f'<span style="font-family:{FH};color:{hdr_col};-webkit-text-fill-color:{hdr_col};'
            f'font-size:.95rem;font-weight:700;margin-left:4px">{q["question"]}</span></div>'
            f'</div>'
        )

        sel = st.radio(
            f'Options for {qid}',
            q["options"],
            key=f"mcq_{qid}",
            index=answered if answered is not None else None,
            label_visibility="collapsed",
        )
        if sel is not None:
            sel_idx = q["options"].index(sel)
            st.session_state.mcq_answered[qid] = sel_idx
            if study_mode or sel_idx == q["answer"]:
                correct_txt = q["options"][q["answer"]]
                col = "#28a745" if sel_idx == q["answer"] else "#dc3545"
                st.html(
                    f'<div style="background:rgba(40,167,69,0.08);border-left:3px solid {col};'
                    f'border-radius:5px;padding:9px 13px;margin:4px 0 12px;{NO_SEL}">'
                    f'<span style="color:{col};-webkit-text-fill-color:{col};font-weight:700">'
                    f'{"âœ… Correct!" if sel_idx==q["answer"] else f"âŒ Correct answer: {correct_txt}"}</span><br>'
                    f'<span style="font-family:{FB};font-size:.86rem;color:#e6f1ff;'
                    f'-webkit-text-fill-color:#e6f1ff;line-height:1.6">{q["explanation"]}</span></div>'
                )
            elif sel_idx != q["answer"]:
                st.html(
                    f'<div style="background:rgba(220,53,69,0.08);border-left:3px solid #dc3545;'
                    f'border-radius:5px;padding:8px 12px;margin:4px 0 12px;{NO_SEL}">'
                    f'<span style="color:#dc3545;-webkit-text-fill-color:#dc3545;font-weight:600">'
                    f'Incorrect. Keep going!</span></div>'
                )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN TAB
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def tab_edu_hub():
    explainer_edu_hub()

    render_card("ğŸ“š Education Hub â€” Hypothesis Testing Reference",
        p(f'Complete visual reference for {hl("hypothesis testing")} concepts, '
          f'formulas, and finance applications. Use alongside the calculator tabs.') +
        three_col(
            ib(f'<span style="color:#FFD700;-webkit-text-fill-color:#FFD700;font-weight:600">ğŸƒ Concept Cards</span><br>'
               + p(f'{bdg(f"{sum(len(v) for v in CONCEPT_CARDS.values())} cards","gold")} across 3 themes'), "gold"),
            ib(f'<span style="color:#ADD8E6;-webkit-text-fill-color:#ADD8E6;font-weight:600">ğŸ“– Glossary</span><br>'
               + p(f'{bdg(f"{len(GLOSSARY)} key terms","blue")} with definitions + examples'), "blue"),
            ib(f'<span style="color:#28a745;-webkit-text-fill-color:#28a745;font-weight:600">ğŸ“ + ğŸ—º + ğŸ“</span><br>'
               + p(f'Formula Sheet Â· Decision Guide Â· {bdg(f"{len(MCQ_BANK)} MCQs","green")}'), "green"),
        )
    )

    mode = st.radio("Section",
                    ["ğŸƒ Concept Cards", "ğŸ“– Glossary", "ğŸ“ Formula Sheet",
                     "ğŸ—º Decision Guide", "ğŸ“ MCQ Quiz"],
                    horizontal=True, key="edu_mode")

    if "Concept"  in mode: _section_concept_cards()
    elif "Gloss"  in mode: _section_glossary()
    elif "Formula"in mode: _section_formula_sheet()
    elif "Decision"in mode:_section_decision_guide()
    else:                   _section_mcq()
